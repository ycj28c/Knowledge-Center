https://www.jiuzhang.com/qa/627

### 要求
设计一个只读的lookup service. 后台的数据是10 billion个key-value pair, 服务形式是接受用户输入的key，返回对应的value。已知每个key的size是0.1kB，每个value的size是1kB。要求系统qps >= 5000，latency < 200ms.

给的机器
```
commodity server
8X CPU cores on each server
32G memory
6T disk
```

### 解决方案
本质上是一个分布式的文件管理系统，和GFS的处理一样，是Master-slave的结构，Master存放文件key，然后有多个chunk服务器只存放chunk。

本题简化了GFS：  
1.因为是lookup，只涉及到读取，所以所有数据都可以存满disk。  
2.value很小，所以不涉及到拆分value，直接完整的放到各服务器即可。  

核心是计算题，要满足：  
1.qps >= 5000  
2.latency < 200ms  

##### 计算存储

存储所有key需要 10 billion * 0.1kb = 1TB  
存储所有value需要 10 billion * 0.1kb = 10TB  

一个disk可以存放6T，理论上两个disk（服务器）就能够存放下所有的内容  

至此，我们需要至少2台机器。如果考虑1个数据3份拷贝，那么也就是6台机器。

##### 计算latency（单次获取key的时间计算）

首先的常识是普通磁盘的寻轨需要10ms，表示每个地址需要10ms让磁头移动过去（如果使用ssd固态硬盘这个时间是0.2ms）。  

然后搜索这个key在磁盘的位置也需要时间，假设文件的排列是有序的，有两种搜索方式：  
1.从disk进行搜索  
在磁盘通过二分法搜索，需要log(10billion) ~= 33，也就是搜索33次才能找到这个key，每次搜索需要10ms，那么就是330ms。   
查看一个文件的总时间就是330ms + 10ms（开始读文件需要一次磁头读取时间） + 0.5ms（同一个数据中round trip时间） = 340.5ms  
注意340.5ms的单key读取时间超过了200ms的latency的要求了，是不满足要求的。  

2.将key的地址信息存放到memory  
这样的寻找时间可以忽略不计，搜索文件的时间就降到了10.5ms左右了。  

不过memory是有上限的，要看是否能够存下。一台机器的内存是32GB，那么40台机器 = 1280GB就能保证存放下所有的key索引了（假设地址8个Byte就够了）  
8Byte * 10 billion = 74GB   
1TB + 74GB < 1280GB   

至此，我们需要至少40台机器。

##### 计算QPS
一个服务器获取一个文件的时间是10.5ms，磁盘读取内容的速度大概30MB/s，因为文件很小1KB所以这个读取时间可以忽略。

那么单机QPS就是：  
1s / 10.5ms ~= 100 qps  
8个CPU似乎没啥用哈，瓶颈在磁盘。所以单机可以上多块硬盘，这里用2块（感觉具体多少块硬盘还可以深入讨论）  
2个disk的QPS可以提升到 200 qps。

再看我们的要求是5000QPS，目前40 * 200 = 8000是可以满足要求的。

至此，我们需要至少40台机器。就可以满足设计的需求了。


